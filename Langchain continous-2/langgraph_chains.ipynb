{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chain\n",
    "Review\n",
    "We built a simple graph with nodes, normal edges, and conditional edges.\n",
    "\n",
    "Goals\n",
    "Now, let's build up to a simple chain that combines 4 concepts:\n",
    "\n",
    "Using chat messages as our graph state\n",
    "Using chat models in graph nodes\n",
    "Binding tools to our chat model\n",
    "Executing tool calls in graph nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Name: Model\n",
      "\n",
      "So you said you were researching ocean mammals?\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "Name: Lance\n",
      "\n",
      "Yes, that's right.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Name: Model\n",
      "\n",
      "Great, what would you like to learn about.\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "Name: Lance\n",
      "\n",
      "I want to learn about the best place to see Orcas in the US.\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "from langchain_core.messages import AIMessage, HumanMessage\n",
    "\n",
    "messages = [AIMessage(content=f\"So you said you were researching ocean mammals?\", name=\"Model\")]\n",
    "messages.append(HumanMessage(content=f\"Yes, that's right.\",name=\"Lance\"))\n",
    "messages.append(AIMessage(content=f\"Great, what would you like to learn about.\", name=\"Model\"))\n",
    "messages.append(HumanMessage(content=f\"I want to learn about the best place to see Orcas in the US.\", name=\"Lance\"))\n",
    "\n",
    "for m in messages:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "os.environ[\"GROQ_API_KEY\"]=os.getenv(\"GROQ_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Orcas, also known as killer whales, can be seen in various locations along the coast of the United States. However, some of the best places to see them are:\\n\\n1. **Puget Sound, Washington**: This area is famous for its resident orcas, particularly the Southern Resident orca population, which is known to frequent the waters between Washington State and Vancouver, British Columbia. The best times to see them are from late spring to early fall.\\n\\n2. **San Juan Islands, Washington**: Close to the Puget Sound, these islands offer excellent opportunities for whale watching tours. Organizations like the Whale Museum and the Center for Whale Research in Friday Harbor provide educational tours and information.\\n\\n3. **Seattle, Washington**: From Seattle, you can take whale watching tours that often lead to the San Juan Islands and the waters of the Puget Sound.\\n\\n4. **Kenai Fjords National Park, Alaska**: This area offers a different experience with orcas that are part of the transient population, which feeds on marine mammals rather than fish. Tours from Seward, Alaska, can take you into the park.\\n\\n5. **Monterey Bay, California**: While orcas are not as frequently seen here as in the Pacific Northwest, they can be spotted, especially in the fall and winter months when they move into the bay in pursuit of their prey.\\n\\n6. **Santa Cruz, California**: Similar to Monterey Bay, sightings are less frequent, but there are still opportunities to see orcas from the coast or from whale watching tours.\\n\\nWhen planning a trip to see orcas, it's important to consider the best times of the year and to book tours with reputable operators who prioritize the safety of both the animals and the passengers. Additionally, always check the latest guidelines and regulations, as they can change based on conservation efforts and the animals' behavior.\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 374, 'prompt_tokens': 90, 'total_tokens': 464, 'completion_time': 1.87, 'prompt_time': 0.006731504, 'queue_time': 0.049793626, 'total_time': 1.8767315039999999}, 'model_name': 'qwen-2.5-32b', 'system_fingerprint': 'fp_92412bc7e4', 'finish_reason': 'stop', 'logprobs': None}, id='run-1acc99c1-1961-4c98-839b-7c9dafe51d25-0', usage_metadata={'input_tokens': 90, 'output_tokens': 374, 'total_tokens': 464})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "\n",
    "llm=ChatGroq(model=\"qwen-2.5-32b\")\n",
    "result=llm.invoke(messages)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add(a:int,b:int)-> int:\n",
    "    \"\"\"Add a and b.\n",
    "\n",
    "    Args:\n",
    "        a: first int\n",
    "        b: second int\n",
    "    \"\"\"\n",
    "    return a+b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_with_tools=llm.bind_tools([add])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_qxxm', 'function': {'arguments': '{\"a\": 2, \"b\": 3}', 'name': 'add'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 25, 'prompt_tokens': 192, 'total_tokens': 217, 'completion_time': 0.125, 'prompt_time': 0.011914488, 'queue_time': 0.054323370999999995, 'total_time': 0.136914488}, 'model_name': 'qwen-2.5-32b', 'system_fingerprint': 'fp_92412bc7e4', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-3a3bbb40-11e0-4306-9036-a449328a2030-0', tool_calls=[{'name': 'add', 'args': {'a': 2, 'b': 3}, 'id': 'call_qxxm', 'type': 'tool_call'}], usage_metadata={'input_tokens': 192, 'output_tokens': 25, 'total_tokens': 217})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool_call=llm_with_tools.invoke([HumanMessage(content=f\"What is 2 plus 3\", name=\"Lance\")])\n",
    "tool_call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'add',\n",
       "  'args': {'a': 2, 'b': 3},\n",
       "  'id': 'call_qxxm',\n",
       "  'type': 'tool_call'}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool_call.tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing_extensions import TypedDict\n",
    "from langchain_core.messages import AnyMessage\n",
    "from typing import Annotated\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "class MessageState(TypedDict):\n",
    "    messages:Annotated[list[AnyMessage],add_messages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[AIMessage(content='Hello! How can I assist you?', additional_kwargs={}, response_metadata={}, name='Model', id='4a8224d0-7807-49c3-aa14-af6d55351718'),\n",
       " HumanMessage(content=\"I'm looking for information on generative ai.\", additional_kwargs={}, response_metadata={}, name='Krish', id='55349043-f7d5-4896-a3e8-969fa9eecced'),\n",
       " AIMessage(content='Sure, I can help with that. What specifically are you interested in?', additional_kwargs={}, response_metadata={}, name='Model', id='294c1ce4-60b3-49ff-85a0-61566fbc0274')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial_message=[AIMessage(content=\"Hello! How can I assist you?\", name=\"Model\"),\n",
    "                    HumanMessage(content=\"I'm looking for information on generative ai.\", name=\"Krish\")\n",
    "                   ]\n",
    "# New message to add\n",
    "new_message = AIMessage(content=\"Sure, I can help with that. What specifically are you interested in?\", name=\"Model\")\n",
    "\n",
    "add_messages(initial_message,new_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "    \n",
    "# Node\n",
    "def tool_calling_llm(state: MessageState):\n",
    "    return {\"messages\": [llm_with_tools.invoke(state[\"messages\"])]}\n",
    "\n",
    "# Build graph\n",
    "builder = StateGraph(MessageState)\n",
    "builder.add_node(\"tool_calling_llm\", tool_calling_llm)\n",
    "builder.add_edge(START, \"tool_calling_llm\")\n",
    "builder.add_edge(\"tool_calling_llm\", END)\n",
    "graph = builder.compile()\n",
    "\n",
    "# View\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "What is 2 minus 3\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "To calculate 2 minus 3, we can think of it as adding 2 and the opposite of 3, which is -3. Thus, the operation becomes 2 + (-3). Since we only have an addition function available, we can use it by providing 2 as the first number and -3 as the second number.\n",
      "\n",
      "However, since the question is about subtraction and our available tool only supports addition, let's directly compute the result without calling a function, as the operation is straightforward.\n",
      "\n",
      "2 minus 3 equals -1.\n"
     ]
    }
   ],
   "source": [
    "messages=graph.invoke({\"messages\":HumanMessage(content=\"What is 2 minus 3\")})\n",
    "for m in messages['messages']:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"]=os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"Multiply a and b.\n",
    "\n",
    "    Args:\n",
    "        a: first int\n",
    "        b: second int\n",
    "    \"\"\"\n",
    "    return a * b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tools\n",
    "Tools are useful whenever you want a model to interact with external systems.\n",
    "\n",
    "External systems (e.g., APIs) often require a particular input schema or payload, rather than natural language.\n",
    "\n",
    "When we bind an API, for example, as a tool we given the model awareness of the required input schema.\n",
    "\n",
    "The model will choose to call a tool based upon the natural language input from the user.\n",
    "\n",
    "And, it will return an output that adheres to the tool's schema.\n",
    "\n",
    "Many LLM providers support tool calling and tool calling interface in LangChain is simple.\n",
    "\n",
    "You can simply pass any Python function into ChatModel.bind_tools(function)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "RateLimitError",
     "evalue": "Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRateLimitError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m llm \u001b[38;5;241m=\u001b[39m ChatOpenAI(model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpt-4o\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m result\u001b[38;5;241m=\u001b[39m\u001b[43mllm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mHello\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m result\n",
      "File \u001b[0;32m~/Documents/AgenticAiWorkspace/venv/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py:307\u001b[0m, in \u001b[0;36mBaseChatModel.invoke\u001b[0;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[1;32m    296\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21minvoke\u001b[39m(\n\u001b[1;32m    297\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    298\u001b[0m     \u001b[38;5;28minput\u001b[39m: LanguageModelInput,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    302\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    303\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m BaseMessage:\n\u001b[1;32m    304\u001b[0m     config \u001b[38;5;241m=\u001b[39m ensure_config(config)\n\u001b[1;32m    305\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[1;32m    306\u001b[0m         ChatGeneration,\n\u001b[0;32m--> 307\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    308\u001b[0m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    309\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    310\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcallbacks\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    311\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtags\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    312\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    313\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrun_name\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    314\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrun_id\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    315\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    316\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mgenerations[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m    317\u001b[0m     )\u001b[38;5;241m.\u001b[39mmessage\n",
      "File \u001b[0;32m~/Documents/AgenticAiWorkspace/venv/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py:843\u001b[0m, in \u001b[0;36mBaseChatModel.generate_prompt\u001b[0;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    835\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mgenerate_prompt\u001b[39m(\n\u001b[1;32m    836\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    837\u001b[0m     prompts: \u001b[38;5;28mlist\u001b[39m[PromptValue],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    840\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    841\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[1;32m    842\u001b[0m     prompt_messages \u001b[38;5;241m=\u001b[39m [p\u001b[38;5;241m.\u001b[39mto_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[0;32m--> 843\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_messages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/AgenticAiWorkspace/venv/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py:683\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[0;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[1;32m    680\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(messages):\n\u001b[1;32m    681\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    682\u001b[0m         results\u001b[38;5;241m.\u001b[39mappend(\n\u001b[0;32m--> 683\u001b[0m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    684\u001b[0m \u001b[43m                \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    685\u001b[0m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    686\u001b[0m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    687\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    688\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    689\u001b[0m         )\n\u001b[1;32m    690\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    691\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "File \u001b[0;32m~/Documents/AgenticAiWorkspace/venv/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py:908\u001b[0m, in \u001b[0;36mBaseChatModel._generate_with_cache\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    906\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    907\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39msignature(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate)\u001b[38;5;241m.\u001b[39mparameters\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 908\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    909\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    910\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    911\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    912\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(messages, stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/Documents/AgenticAiWorkspace/venv/lib/python3.12/site-packages/langchain_openai/chat_models/base.py:792\u001b[0m, in \u001b[0;36mBaseChatOpenAI._generate\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    790\u001b[0m     generation_info \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mheaders\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mdict\u001b[39m(raw_response\u001b[38;5;241m.\u001b[39mheaders)}\n\u001b[1;32m    791\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 792\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpayload\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    793\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_chat_result(response, generation_info)\n",
      "File \u001b[0;32m~/Documents/AgenticAiWorkspace/venv/lib/python3.12/site-packages/openai/_utils/_utils.py:279\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    277\u001b[0m             msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    278\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[0;32m--> 279\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/AgenticAiWorkspace/venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py:879\u001b[0m, in \u001b[0;36mCompletions.create\u001b[0;34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, reasoning_effort, response_format, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    837\u001b[0m \u001b[38;5;129m@required_args\u001b[39m([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m], [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    838\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcreate\u001b[39m(\n\u001b[1;32m    839\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    876\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[1;32m    877\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatCompletion \u001b[38;5;241m|\u001b[39m Stream[ChatCompletionChunk]:\n\u001b[1;32m    878\u001b[0m     validate_response_format(response_format)\n\u001b[0;32m--> 879\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    880\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/chat/completions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    881\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    882\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m    883\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    884\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    885\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43maudio\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    886\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfrequency_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    887\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunction_call\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    888\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunctions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    889\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogit_bias\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    890\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    891\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_completion_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    892\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    893\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    894\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodalities\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodalities\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    895\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    896\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mparallel_tool_calls\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    897\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprediction\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    898\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpresence_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    899\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mreasoning_effort\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning_effort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    900\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresponse_format\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    901\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    902\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mservice_tier\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    903\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstop\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    904\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstore\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    905\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    906\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    907\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    908\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtool_choice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    909\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtools\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    910\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_logprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    911\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_p\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    912\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    913\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    914\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletionCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    915\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    916\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    917\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m    918\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    919\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    920\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    921\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    922\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/AgenticAiWorkspace/venv/lib/python3.12/site-packages/openai/_base_client.py:1290\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1276\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpost\u001b[39m(\n\u001b[1;32m   1277\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1278\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1285\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1286\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[1;32m   1287\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[1;32m   1288\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[1;32m   1289\u001b[0m     )\n\u001b[0;32m-> 1290\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/Documents/AgenticAiWorkspace/venv/lib/python3.12/site-packages/openai/_base_client.py:967\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    964\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    965\u001b[0m     retries_taken \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m--> 967\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    968\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    969\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    970\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    971\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    972\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries_taken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    973\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/AgenticAiWorkspace/venv/lib/python3.12/site-packages/openai/_base_client.py:1056\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1054\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m remaining_retries \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_retry(err\u001b[38;5;241m.\u001b[39mresponse):\n\u001b[1;32m   1055\u001b[0m     err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m-> 1056\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_retry_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1057\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1058\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1059\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries_taken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1060\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresponse_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1061\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1062\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1063\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1065\u001b[0m \u001b[38;5;66;03m# If the response is streamed then we need to explicitly read the response\u001b[39;00m\n\u001b[1;32m   1066\u001b[0m \u001b[38;5;66;03m# to completion before attempting to access the response text.\u001b[39;00m\n\u001b[1;32m   1067\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mis_closed:\n",
      "File \u001b[0;32m~/Documents/AgenticAiWorkspace/venv/lib/python3.12/site-packages/openai/_base_client.py:1105\u001b[0m, in \u001b[0;36mSyncAPIClient._retry_request\u001b[0;34m(self, options, cast_to, retries_taken, response_headers, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1101\u001b[0m \u001b[38;5;66;03m# In a synchronous context we are blocking the entire thread. Up to the library user to run the client in a\u001b[39;00m\n\u001b[1;32m   1102\u001b[0m \u001b[38;5;66;03m# different thread if necessary.\u001b[39;00m\n\u001b[1;32m   1103\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(timeout)\n\u001b[0;32m-> 1105\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1106\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1107\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1108\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries_taken\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1109\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1110\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/AgenticAiWorkspace/venv/lib/python3.12/site-packages/openai/_base_client.py:1056\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1054\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m remaining_retries \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_retry(err\u001b[38;5;241m.\u001b[39mresponse):\n\u001b[1;32m   1055\u001b[0m     err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m-> 1056\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_retry_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1057\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1058\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1059\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries_taken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1060\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresponse_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1061\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1062\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1063\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1065\u001b[0m \u001b[38;5;66;03m# If the response is streamed then we need to explicitly read the response\u001b[39;00m\n\u001b[1;32m   1066\u001b[0m \u001b[38;5;66;03m# to completion before attempting to access the response text.\u001b[39;00m\n\u001b[1;32m   1067\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mis_closed:\n",
      "File \u001b[0;32m~/Documents/AgenticAiWorkspace/venv/lib/python3.12/site-packages/openai/_base_client.py:1105\u001b[0m, in \u001b[0;36mSyncAPIClient._retry_request\u001b[0;34m(self, options, cast_to, retries_taken, response_headers, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1101\u001b[0m \u001b[38;5;66;03m# In a synchronous context we are blocking the entire thread. Up to the library user to run the client in a\u001b[39;00m\n\u001b[1;32m   1102\u001b[0m \u001b[38;5;66;03m# different thread if necessary.\u001b[39;00m\n\u001b[1;32m   1103\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(timeout)\n\u001b[0;32m-> 1105\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1106\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1107\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1108\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries_taken\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1109\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1110\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/AgenticAiWorkspace/venv/lib/python3.12/site-packages/openai/_base_client.py:1071\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1068\u001b[0m         err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m   1070\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRe-raising status error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1071\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error_from_response(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1073\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_response(\n\u001b[1;32m   1074\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[1;32m   1075\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1079\u001b[0m     retries_taken\u001b[38;5;241m=\u001b[39mretries_taken,\n\u001b[1;32m   1080\u001b[0m )\n",
      "\u001b[0;31mRateLimitError\u001b[0m: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}"
     ]
    }
   ],
   "source": [
    "llm = ChatOpenAI(model=\"gpt-4o\")\n",
    "result=llm.invoke(\"Hello\")\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_with_tools = llm.bind_tools([multiply,add])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph import MessagesState\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import ToolNode\n",
    "from langgraph.prebuilt import tools_condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAKEAAAFNCAIAAADnwpisAAAAAXNSR0IArs4c6QAAIABJREFUeJztnXdAE+f/x59LLiQhCSOMsAQHoiAUUBSqKFpFLW6tWme1amtd9VutVmtr6XDVWrWtdmhd2OGqFqvgHmBBEVCpgLJlk0H2Tn5/xB+CBgxwuecyXn/B5e553vDO57m75/k8z4Po9Xpgx6ohwRZgx+zYPbZ+7B5bP3aPrR+7x9aP3WPrB4Ut4HlEfLWIp5aJtFKxRqOyjDc7lIKQUcSRRXZ0QtkcCp1JrP8qQpD/YkOVsuS+pCRPynBCtRq9oxOZwUKpdBIx1L0ElIpIBBqZWCsTaWQSLZ1J7h7K6BnBZLpSYEsDhPBYxFffSuaRSMDF06F7KMPdlwpXT+epLpaX5En5tUoXD4eB49xQCuQbImSPb6fw8m+LB45z6xnJgijDTNy70XgrmTd4knvoQGeIMmB6fOq7yuBop+ABTrAE4MPtVL6Yrx4+gwNLALRm5Od1JdEJblZvMABgwCi2d3f6uV9rYAmAE8c/fVQ8Y00XJ7YD/lXDouCOKO+W6I33/fCvGoLHJ7+rfDXBzacHHed6ofMgXcirVg6d6olzvXi31ZkpvD4xTjZoMAAgbJCzI4ucf1uEc724eizkqguzxL37W/89uDX6Dne9drwB50px9fhWMnfgOHc8ayQaKIXUb4Rr5nkenpXi53H9EwXqQAoMZ+JWIzEZMIpdW6ZQq3S41Yifx8X3pK4c/Pr28vLylEolrMvbhsYklz6QmqnwF8HP45I8SfdQnII4OTl53rx5crkcyuUvpXsooyTP6jwW1KtYrijbC6cX4g6HoOFN0nwRbKD7K0whF78xNZw8FvHUACDmKLm8vHzx4sWxsbEJCQmbNm3S6XTJyclbtmwBAIwYMSIqKio5ORkAkJubu2zZstjY2NjY2HfffTc/P99weWNjY1RU1JEjRzZs2BAbG7to0SKjl2MLmYzIJTpJowbzko2C00inTKR1dCKbo+QvvviirKxs1apVUqk0KyuLRCINGjRo9uzZSUlJO3fuZDKZ/v7+AIDq6mqlUrlw4UISiXT8+PEVK1YkJyfTaDRDIfv37586deqPP/5IJpM5HM6Ll2MOw4ksFWlZuAw+4uSxVKxhsMxSV3V1de/evSdNmgQAmD17NgCAzWb7+fkBAEJDQ11cXAynvf766wkJCYafQ0JCFi9enJubGxMTYzgSFha2dOnSpjJfvBxzGM6oVGhdcQz0gEI1S1udkJBw8ODBbdu2LVy4kM1mt3YagiBXr15NSkoqLS11dHQEAPB4z15SBwwYYA5tbeBAI+l11nU/pjHJYr5ZvrZLly794IMPLly4MH78+GPHjrV22r59+z788MOQkJAdO3asXLkSAKDTPXtDpdPx7lsVctWOTjgFGE4eM1ioVGwWjxEEmTlz5pkzZ+Li4rZt25abm9v0UdODq1KpPHDgwMSJE1etWhUREREWFmZKyWZ97pWKNAwr85jpijrQzFKX4T2HwWAsXrwYAFBQUNAUlw0NT3uG5XK5UqkMDg42/NrY2PhcHD/Hc5ebA5YrhelslofQF8Hpq+ThS60qkksaNUwXjGtcu3Ytk8mMiYlJS0sDABiMDA8PJ5PJ27dvHz9+vFKpnDJlSmBg4B9//OHm5iaRSH7++WcSiVRUVNRamS9ejq3m8nwpGUXIeOV5kT/77DN8ahJxNQqZluNPw7bYysrKtLS0lJQUuVy+fPnyoUOHAgCcnJw4HM7Fixdv3rwpEonGjh3bt2/f9PT0Y8eOlZeXL1++PCAg4OTJk7NmzVKr1YcPH46NjQ0JCWkq88XLsdWcc63RrwfdE+t/RWvglyPw5JGsKFcybBreI+QEJPnn6mHTPJguOPXe45ft3SXIMfM8v6ZU7t3N+ENsY2PjxIkTjX7k5+dXWVn54vG4uLjExESslT7PwoULjTbswcHBTf1lzYmMjPz2229bKy3vlpDpguJmMN65PjWl8vS/ea3lNGm12rq6OqMfIYhxnXQ63dXVFWuZz9PQ0KBWq01X5eDg4O7e6jD5z+tK3vo0gErH6YELQj7X9RMN3cIc/Xsx8KyUODxIF6oUun7Dzf69bA7e+Vxxb3hcOlovFeHUjUcoKgplJfclOBsMJ796xhr/37dW4F8vXMQC9cWkugnv+eJfNZz8apVce2Rz+ay1ATQGfrcliNSVKy4k1c1a508imaXTvm2gzYWRNGp+/7pi7ELv1h6zrYbCu6J7N4TT/tcFlgDIc9qu/FEvE2sGjnPHLUUETyofy9KTeX6B9EHjYWajwp+bWvqf9FYyt1sfBieA1i2UAaU1wxaFTFuaJ60pVQi56kHj3HDrz2oN+B4bKMoVP8qWlOZJg6OdUAeE4YQynMhUOpkQ4l4GmYxIRRqZSCMVasUCdU2polsoI6gfy7+XI2xpgEAeN1GWLxXWq6UijVSk1ar1Wi2W8jQaTV5eXkREBIZlAgDoDLJer3d0QhnOZHdvKtFm+hDOY7PS2Ng4ZcqUy5cvwxaCK/Z1fawfu8fWj215jCBIr169YKvAG9vyWK/XFxYWwlaBN7blMYIgzs4wl9iBgm15rNfrhUIhbBV4Y1seIwji4+MDWwXe2JbHer2+uroatgq8sS2PEQQJDQ2FrQJvbMtjvV6fl5cHWwXe2JbHtolteYwgSBsZk9aKbXms1+u5XC5sFXhjWx4jCOLh4QFbBd7Ylsd6vd6ssxGJiW15bJvYlscIgvTo0QO2CryxLY/1en1xcTFsFXhjWx7bJrblMYIgTStG2A625bFerzc6Y9i6sS2PbROb87hPnz6wJeCNzXn833//wZaANzbnsQ1iWx7bc2+tH3vurR3rxLY8tudXWz/2/GrrB0GQnj17wlaBN7blsV6vf/z4MWwVeGNbHtsmtuUxgiAcDrT9xGFhWx7r9frWll21YmzLYwRB7GMSVo5er7ePSVg59ji2fuxxbP0gCGLYZ8+msIk12BYuXFhdXY2iqE6nEwgEbDYbQRC1Wn3+/HnY0vDAJuJ4+vTpYrG4urq6trZWqVTW1NRUV1eTyTaxdLateBwfH//i9AjMV80kLDbhMQBgxowZhu1SDXA4nFmzZkFVhB+24vGoUaMCAgIMP+v1+n79+tlOMr2teAwAmDt3LoPBAAB4eXnNmDEDthz8sCGP4+PjDaEcGRlpO0Fs0l58aqWOV6OSSbS46DEvk0YtBrK/Rg2eW5Inha2lsyAAMF1RNseBjL5kd4aXvB/fONVQlCthOKN0Jn47M9oxBQc6iV+jRBCkd39m5LC29gVry+PzB2pcvWl9XsV7XzE77eLfs/XObmj0aHZrJ7Tq8cWjdS4cau/+LuaUZwcbMv6pd/Oi9H3NeDQaf+aqe6JQyHV2gy2FmDGej3MkaqXxZybjHvNrVCheO6nbwQS9HvDrjGzg26rHUpHGxd0KN06zYtx9aCK+8d1ojXus0wKtxvrHo6wJpUILdMY/sjfI1o/dY+vH7rH1Y/fY+rF7bP3YPbZ+7B5bP3aPrR+7x9aP3WPrx+6x9YOlxw/z85RKZWdKuHb90rDhURUVZdiJesr8BdM+/2Kd4WehsHHY8Kgzf59o+nTL1s8WvzcH50pxAzOPU1KTly6bp1DIsSoQTxwZDEdHBmwV5gKzLK1ORjBcViz7sL2X6PX66poqXx8LmCGHjccpqck7d20BAEycPAIAsHbNxtGjxgEALlz45+jvB6qrK93c3MckTJo1cz6JRAIAaDSaAwd/TL1wVihsDAjoNu+td2MHDW1XjQqF4kjSvqtXLzRw6zkc75HxY2bNnM/jcfcf2JOZmS6VSrp0CZg5Y/6I4aNfWtSbM8fW1dWGhoZ/t2s/AGDchKEr31+XlnY1IzONwWCOGzvlrbmLDGc+zM/7Yc83JSWP3djuXbv1KCoqPHzwlINDRwbaT5z87cbNKyPjxxw6/LNQ2NijR9CCt5dcunQ+Pf0aSqGMjB/zzqLlWM3Iwqatjh4waNrU2QCAzV/t3L1zX/SAQQCA1NSzm7du7Nmz9ycbNg2Ni//1wN6jvx0wnL/9my//PHZk7JhJH6//0svL55NPV9+/n2N6dVqtdv3HK48dTxo8+LU1qz+NGzL8SWU5mUzWaDUFBf9NGP/Ge++udHJy/mrThvyCl882XvXBhp6BLRZK3bJ1Y2Bgr53f/hI/IuHgoZ8yMtIAAHV1tas/fA9F0Y/XfRkZ2T89/fr4cW90zGADDx7kXrmS+tmnWz9am1hRUfrhmqUODg7bt++dOGHaseNJKanJHS75ObCJY1dXto+PHwAgODjU2dnF0JTt+/WHsLCIDeu/BAAMGfyaWCz6489DUybP4HLrUy+cnTtn4by33gUAxA0ZPnvupIOHftrxzY8mVnf9xuWc3KwPV3+S8PqE5sd9vH0P/nocQRAAwOuvT5g0ZUR6+rXg3i9ZOKB/VMzx40nyZk8SCa9PmDVzPgAgsEfQP+dO3876NyYm9uKlc3K5fOMnW9hst0GD4u7dz87ITJs5Y16H/mFP+fSTzS4urn36vHL7zq2MjLT/rVyHIEivoOALF85mZ98ekzCxM4U3Ya6s6crKCi63Yfq0Zw+r/fu/eu78mcqqisLChwCA2NhhhuMIgvSPirl46Zzphd++c4tKpY4aOfbFj4qKHx089JOhCq1Wy+fzOiCeRqMbfiCTyR4enjxuAwCgoaGOwWCw2W7/vx+6X11dTQcKb46DA/XpDxQHCoVi+HYCANw9PIXCxk4W3oS53o8lUgkAwMXlWdIvi+UEAOA21EulEgCAa7OPnJycZTKZVGrq3AUBn+fu5vHi7So7586SpW+pVao1H25M3LjNyclZp28l/8VkUDKq1WkBAL6+XaRSaUlJEQBArVYXFRX26BHUycJbA0GwnPuPcRw3KfP04BheCps+Egj4Bqfd3T0BACKR0N396faWfD4PRVEajWZiLUwmiy8wEqBHjuzz8fHb9NVOFEUBAPT/D0dMGDVy7PETR9dvWDkyfkzuvbsajWbe3HcwLN98YBbHhn8ol/t0x0o3N3cvjvft2+lNJ1y/folGowUG9goODkUQJCMzzXBcpVJlZKb16fMKmUx2oDgY7G+7rsjI/nK5/PKV1KYjGo0GACAUNQb2CDIYrFKpZHKZTvc0jh0oDmKxyPAzilIAAE2/moizs8uypaupVFppaXFUv5hffvrNz8+/7Us6XykmYOZxn9BwMpn8/Z7tqaln/04+CQCY99a7t+/8+/X2L65dv7Tj201p6demT5tLp9N9ffxGjRx78NBPR5L2X76S+tG6FXw+b+6cRQCAbt0DSSTSt7s25+RmtVFX/IiEHj16btm68Yc9O1JTz+79cefiJXN0Ol1ERFRGZtq582fS0q59uHapWCwqKy02NC2Bgb2y7mb+sGeHWq1mMBi+Pn7Hjiclnz1l+h+YX/Dftq8TZ745b+jQ+C5dAmpqqrTal8zz63ylmICZx74+fqs++PjJk/Lvf9h+7dpFAMCoUWNXvv/RvfvZX23acOfOv+8sWt70orny/Y/Gj3vjr9N/btm6USIRb/ry276R/QEA3l4+az/cqFQqDa8rrUGlUr/Z/uOokWMvXjq3c/eW23duDRk8XKPRvD3vvf5Rr373/de7v9/Wr2/0Z59u5fG5hq/LwgVLB8cOS0n529BX8/HHX/n5+adeOGv6H+jF8fb29t36deKXX338+Rfr3v/foveWzFUoFG1c0vlKMcH4vf12Kl+lAOFDW50mZZtotVrDg55Wq72ZdjXx84++2b7X8O2Ezo2TtUERzJ59mS9+RNwZpytWLiwtLXrx+MCBcevWJuKvp6Ki7P3/LXo1ZnBgjyClSnnjxmUajVZfXzdugvEeuu93HwgI6Ia7TCMQ1+NPN2xWa4xM4MH2adl0GAzm8NdGZ2TcvHjpHJPJCguNWLlyXYB/t/DwvkbP93D3xF2jcexttZXQRlttzxGwfuweWz92j60fu8fWj91j68fusfVj99j6sXts/dg9tn7sHls/xvuraY5knbazWTJ28ITOIKMOxhdHNR7Hzu5oTZlFzniwWcoLpG4+xhOBjXvs19NRJbeGxYxtBBFP5e7t4MSmGP3UuMdkFIkezb5wuMrM2uxggF6vv/pn7eDJHq2d0FaOZ1WxPPVwbUQc24VDdWQRd6TZNkEQIOSpxHz1v8kNb30awHI1HsQvX6Nc0qjJviKoLVPIxERsupVKpYODQ1PquTnQabVanY5CafU/CAtHJzJKIfl0p8UkuLV9pgXv07Zjxw58tvBJTEyMjIwcP368uSsyExbscVMGnZXVhTmW2gdy8+bNl6Y3Y4hIJMrOzsatOmyxSI/37t0rkUg6My+0vbi6umZlZZ09i3dqNCZYXlstkUgaGhq6dYOQ1lpQUBAYGGiYa2NBWF4c8/n8pl31cKZr1661tbVQqu4MFubxF198kZ2dbVhwAn9oNNrhw4dPnjwJpfYOY0keFxcX+/v7T5yIzez6jrF+/fr79++r1cZ35yAmlnc/ttNeLCaOT5w4cfHiRdgqnvLNN98UFhbCVmEqluFxSUnJ6dOn4+PjYQt5yrhx4z777DPYKkzF3lZbPxYQx1wut6wM+xU0O4lOpxMIBLBVmIQFeDx+/Hhvb2/YKp6HRCLt2bPn1Cm8F37oAET3OCsr65dffqFSqbCFGGHFihVVVRaQRmG/H1s/hI7j/fv33759G7aKtqirq9u7dy9sFS+BuB6XlJSkpKQMGDAAtpC24HA4d+/ezclpx4Ku+EPctlqpVKIoSvyReT6fz+fzAwMDYQtpFYJ6rNFoBAKBh0eruYZ2TIegbfXmzZvT09NNOJEQHD58+MqVK7BVtAoRPVYqlRKJBO74Urt45ZVXjh49CltFqxC0rbY4iJzUR8Q4Tk5OlkgksFW0D7lcLpPJYKswDuE8zsvLO3HiBJNpZC0xIvPgwYM1a9bAVmEcwnksl8vXrl0LW0W7efXVV+vq6oh547Pfj60fYsVxY2Pj999/D1tFBxGLxY2NmG30gSHE8vjmzZtcLhe2ig5SXl6+a9cu2CqMQCyPQ0NDly1bBltFBwkJCamoqICtwgj2+7H1Q6w4XrVqFWwJnaKwsJCAEykI5HFZWRkB87baRVZW1m+//QZbxfMQyGNnZ+ctW7bAVtEpoqOj3dxeMqsff+z3Y+uHQHGcnJyckpICW0VnuXTpUtPmcASBQB4/ePDA9G01CcvevXuJ9gZFoOnSkydPdnd3h62iswwfPlwuJ9YShfb7sfVDoLZ6165dBQUFsFV0loqKivLyctgqWkAgj//77z8ruB9nZ2cfPnwYtooWwL8fT506FUVRFEUVCsXXX3+NIIgh5fbgwYOwpXWE4OBgoiWxwPdYKpXW19c3P6LT6SZPngxPUafo1atXr169YKtoAfy2esCAAc+9UPr6+r799tvwFHUKmUxGtDxc+B7Pnz/fy8ur+ZG4uDgfHx94ijqFVqv9/PPPYatoAXyPAwICoqOjm17hfHx83nzzTdiiOg6LxRo2bBhsFS2A7zEAYN68eYbA1ev1Q4YM8fPzg62oU2zcuBG2hBYQwuOAgIBBgwYZ7sQWHcQGbt68Saiuro4/V4v4GgzXBh+fMD0z/f7g2MHODC+xQINVsVRHkgMV7+/xnj17EhMTg4KCcK63NdrtsVig/vcffvE9iW9POr9GhZ0SZELUJiAHJ3dXYlcmAAggISB8iEt4nAuWxbZJdHQ0oebFtK+/upGrOvVd1bDp3i6eDiiFEO38SxHz1fm3BRQKachkix/w6Bjt8FgsUB/fUTl1NYRFhTtPzlWeVqUdNs0Th7qys7N9fHyeeyGESDti8d9/eMNmEG4NJROJHOamVoHqEjwehU6dOkWo1SPa4XHxPamLJ35Lv2MOCUUaKpU4VDRw4EBC9eGY+swl4mt8e9It5R5sFA9fqlyEx5rECQkJONRiOqZ6hiAA06doCKhVerkUj21GsrKyCDUQbsFxSVjS09MJtawY/LFF6yM6OppQ+4oQSIrVEBMTA1tCC+xtNfbcu3fPUt+d7JhITk5OWloabBXPsLfV2BMeHk6oNX7sHmNPZGQkbAktsLfV2FNQUHD37l3YKp5h9xh7cnNzCZW2Z2+rsad3796enngMcJmI3WPsiYiIgC2hBeZtqyUSyaPHne25nb9g2udfrMNIER6Ulpba0PvxwnfePH/+jFmrICDZ2dnnz5+HreIZ5m2rVSrLHqrqGAEBARQKBbaKZ5jR4zdnjhUI+KfPHD995jiH4/XHb2cBADwed++P32beTtdoNGGhEYvfXdm9+9OdGC5c+Ofo7weqqyvd3NzHJEyaNXP+i/scP3lS/u3OzfkFeSyWU0x07Mr3P4K1F3IbREVFwZbQAjN6/NnGbWvWLosI7zf1jVkUBwcAgEKh+GD1YpFI+M6iFTQq7fc/D32wevGRw3+xmKzU1LNbtn02fPjoBW8vefjwwa8H9gIA5sxe8FyZX3/zRUVF2dIlq2QyaU5uFgENBgBUVVWJxeLevXvDFvIUM3rcu1cIiqJubu5hYU+fMy9eOldRUfbN9r19I/sDAMLCImfOHn/q1B9z5yzc9+sPYWERG9Z/CQAYMvg1sVj0x5+Hpkye4ejo2LzM2trqoJ69x46ZBACYNnW2+cR3hoyMjMLCwvXr18MW8hRc4+DevbtMBtNgMADAy8vb379r4aOHlZUVXG7DkMGvNZ3Zv/+rMpmssur5xVPiRyTcycrY/d02gYCPp/J2weFwunfvDlvFM3B9P5ZIJc4urs2PODk587gNEqkEAODiwm46zmI5AQC4DfVBPVu0eAsXLHV1ZScd/fV8yt/vLFoxaeI0HOWbSmxsLGwJLTB7HDfP3/Zw9xSJhM0/5fN5TCbL04MDABAKny3+bAhTg9PNQRDkjSkzjx45M2hg3O7vtj14kGtu/R2Ay+VWVmI626NzmNdjOo3O4z1bj7pPn1fEYlF+fp7h1+Lix1VVT8LCItzc3L043rdvP9vQ6fr1SzQaLTCwFwDAgeIgFosMx5VKJQCAwWDMm7cYAND5DhZzcP36dUItCUI2cc91lUKXnykKiWnfrKHHjwtvpl1BUbSsvISCUiIj+1+9duHylRQ63bGo+NHOnZtRCmXthxvpdDqL6fTn8aSGhjq1Wn3qrz8uXT4/a+bb/aNiAAAFBf9dv3FZKpVERkRtTFyTmZkml8mSk0+WlZfMmb3A09PU6Qi8aqVKru3Wh9GuP6ED1NTUaDSavn37mrsiEzGvx336vFJUVHjx0rnHjwt69+7TrWuPga8OKS0t+jv5RGZmelBQ8KefbPby8gYABAYGubqyr1y9cD7l70YBf+bM+bNnvY0gCAAgJDisuroyLe3qxInTudz6jMy0y1dS5Ar5O4uWx8YONV0Mbh53796dOAa3Y76TWKA5ubtyysqu5pdkLgqzhGKeEocpT2KxWKVSEWcBXCL2IVg6qampP//8M2wVz7B7jD00Gs3Z2Rm2imfYx4+xZ+zYsbAltMAex9ijUCgItSik3WPsOX369J49e2CreIbdY+whk8kMhtnf0EzHfj/GnqlTp8KW0AJ7HGOPSqUy9LkSBLvH2JOUlLRv3z7YKp5h9xh77Pdj6+ett96CLaEF9jjGHplMRqj1Mu0eY8+ePXtOnz4NW8UzTPVYr9O7+VDNLMa8UBxIdCYey1jS6XRXV1cTTsQJU+/HTm6U6iKZWqmj4L6MLFbUP5F7+ePxNV26dCkOtZhOOwwLjGQK6gj02tdetBq9Jy4e19TUiMViHCoykXZ4HDvB/dLRanOKMSOZ5xpYrmSOPw2HurZu3ZqbS6BkwnZ4TKWT53wckPRlUXWxTCrCbBlxs6LT6RuqFDdP1bi4o4PG4bS2cbdu3Qg1/7jd+y2qVbpbf3NLHkhdPB2wXWJUq9ORSAgCsFvcHgCUgjBd0PA45179nk/jtR06vqemQqpFSFj6sWLFikWLFoWFhWFYJpVGwvQ7YxIFBQVdu3al0fC4L5hCx/u5aAyM30O0egXqoKfSLfW5vYmVK1ceOXKEOB5b/D+UgHA4HBaLBVvFMwjUX83hcIg517S9HDp0CLaEFhDof1pXV/fcxouWiEajKSsrg62iBQTy2N/fn1Bb5nSMsrKyjz76CLaKFhDI4+rqakKlT3QMlUoVGhoKW0ULCHQ/DggI6PCLHHEICQkJCQmBraIFBIpjgUAgEolgq+gsdXV1hJp8TCyPnZ2draCtTkpKunHjBmwVLSCQx1QqVSgUmnAioWGz2fb7cau4uroKBALYKjrL/PnzYUt4HgLFsZeXlxW8O+Xn52s0xBqUI5DHbDb7wYMHsFV0isbGxmXLlhFq4x9ieezr61tVVQVbRaeor68fOrQdy1fgQ8fHFjFHr9fPmTMnKSkJthBrg0BxjCCIWq0uKiqCLaTjVFZWcrlcE07EFQJ5DAAIDAy0aI/Xr19fV1cHW8XzEMvj8PBwog3atAs/P78+ffrAVvE8xPI4LCyMUDuctZdNmzbBlmAEYnkcHBxcWlqqUChgC+kIDx8+JFTKbRPE8hgA8Nprr2VmZsJW0RF27dpFtN4PA4TzODY2NjU1FbaKdqPT6bp37060XQYMEOj92IBGoxk0aJCFhjIxIVwcoyg6evRoiwvla9euFRcXw1ZhHMJ5DACYPHnyn3/+CVtFO9Dr9atXr+7RowdsIcYhosfh4eEAgEePHsEWYirV1dX79++HraJVCHc/NnDhwoWrV69u3rwZthBrgIhxDAAYOXJkUVFRSUkJbCEvp7S0lGiTyp+DoB4DAJYsWXLs2DHYKl7OkSNHRo4cCVtFWxC0rTawYMGC5cuXE22r2eeQSCRMJhO2irYgbhwDANauXbt161bYKtpCIpEQf44WofUFBQUNGTLk3LlzsIUYp7GxccKECc/tFkhACN1WGxg0aNDly5eJM523iZSUFF9fX2wnxZsDC/D46tWrKSkpBG+0iQyh22oDw4YNQ1E0JSVCvloLAAAIKklEQVQFtpAW/PDDDxUVz2/5SUwsII4NxMbGXrx4kU6nwxYCAADHjx8vLi4m2hzU1rAYj3Nyck6fPp2YmAhbCAAACIVCQu3u0zYW0FYbiIyM9PLyIsLa3zk5OVqtFraKdmAxHgMA3nvvvcrKSrhzKQ4dOnTz5k02m23CuUTBYtrqJqKjo9PT06HMNxGJRIWFhf3798e/6s5gSXFs4MiRI80fdgYPHmy+uhITE+Pj45t+1el0FmewRXocFBQ0dOjQ3bt3G7pHZDLZJ598Yqa6iouL+Xz+8OHDAQBr1qwh2gIBJmJ5Hhs2NBSLxVFRUUqlEkGQggKz7GbO4/EkEgmCIEKhcODAgUuWLCHa5HETsUiPx40b99dffzX9KpfLzRFhRUVFTctQq1SqKVOmTJ8+HfNacMDyPI6Li6upqWl+RCwWl5aWYl5Rfn5+83UNEAQpLi5OSEjAvCJzY3keDx061Nvbu/nrgFQqffjwIeYVFRQUNK8FQRBPT0+zPuKZCWLNeDeFxMTE8vLy48ePZ2RkVFZWajQanU537949zCtqyqWlUCheXl6jR49+4403iLMDvelYnseG1dpWr17N4/HOnDnzzz//1NfXV1dXa7VaDJcTKS0tlUgkLBbLx8dn4sSJkydPJtoKEKZD0D4QjVpXmid98ljJq1HKJVqUQhLxVcZP1QOtTqvT6SgUCrYa1Go1mUxuI82D5khGKQidiXr4UQN60wKCCbT/XnMI53HlY1n2NVFlgZTFcXTyYJBQhEJFKVQywHTNe0zQa/RqlUaj1GrVWlGdVMyVB0U59XvNhe3lAFtaCwjkcV2F4sZfPJlE797VhcEmxBhiu9Dr9GKerKFIwAmgDnvDneFMlLadEB7r9SAtWVBeIHf2ZrHciZ4e9VIE1WIZTxo+xDk0hhD5moTw+PzBOqEQ8QqyvEfWNnhyr7ZnOD3mdfgjVPDfj68c50kVqJUZDADoEu5V+lCVexP+Sr6Q4/hCUr1YSnbzd4GowazUFnKDIqh9h8L8A2HGce71RgFXb8UGAwC8ernn3RI/eSyDqAGax4J65YNbYk4vnPbHg4hfuPfl3xv0OmjtJTSPb57mO3lbTNpbZyCREIYbI+M8H5oAKLXWVyh4tWpnDkE7hjDHo7trztVGjRrOzkZwPM65LmR3IWgQf75t7IkzWzAv1r2bc+61RsyLNQU4Hpfcl7A8LL6vo10w3RwfZUuhVA3B4yePZEw2lUSG/2qOJ47OVIlQA2XfaAh9qnVlCoabue7ERSV3z13cU137iMVkB3aLej3+PSeWOwBgw1fDp4xbm5d/7WFhOp3GjOk/aeSwhYZLtFrtpWv7M7JOq1TyHt37qdXmWsmR7ceoKpYHReK93SaEYOLVqRGyWQaRHhff+eXwCo5nt2kTPx4ycGZJWc6PB5aqVE89++NUoo9X0JIFP/YNf/3ClV8eFqYbjv919uuL1/b3Dho4aexqBwpNrhCbQxsAQKtBJALbiGOpUENxNsvN+PQ/38RETZo0drXh16DA6K93Ty8syggLGQoAGNB3/PC4eQAAH6+g23fPPCrKCOk1qLK6ICPrr+Fx818fsRgAEBU5prg02xzaAABkB7JEaBsek1AShYZ9vXxBTV1DKZf/JCPrdPPjjcKni4Y7ODwdrySTyc5OnkJRAwDgwcNrAIAhA2c0nY8g5mrbHOioVgNhohQEj9UKLUWF/Z8qlvAAAPHDFr4SMqz5cRbLSFcaiYTqdFoAQGNjLY3GZDji8SKnVmp1VAi9XRA8dnRC1UrsPabTWAAAtVrp6dHV9KsYDFeFQqLWqCio2ZM3NEotyxXCBlYQnrlYLmSNGeLYw93fxdnrTnayUiU3HNFqNRqNuu2r/Hx7AwBy7uOxBKtWrYGSHAKhSk4ArbJUgnmxCIJMSPjfod/XfvfTglcHTNbptFk55/pFjG5+r32R8D4jLl379eSZLbV1Jb7eQWVPHojEDZhrM6AUqzhdXM1UeBtAiONuoQxhrVnG2sJChr49eweZTPn73LeXrv3q6urVvWtk25eQyeSFc3YGBUb/e+fk2dTvSAiJ4WiWsU6VXKPT6tx9qeYovG3g5Agc+7bS0dOFaYGJeR2GVyFku2qGTfPEv2o4uYOvDHbKSZO24XF+YfrRE5++eJyCUtUa43skL1+0j+PZDSuF5y7uuXX75IvH6TRWa50kSxf+5M0JbK1AuVDeZwycfCZouT6Hvyz37OVJYxp/mlWpFBKpkQFXjUaNosZz5Z2dPMlkzL6yUplQqTQyhKDXA6SVPjonlkdr2oS1ErJONnaBN1by2gU0j0v/k6SfFfq94gWldpx5nP5k+ge+TmyMZ3KYCLTBn259mO7eqLgBznAbngieNIYPcYJlMOScvdFzOfxygULSykQmq0BYJ0ER1YCRMLOsIQ/izvnYv/5Rg8YM3V5EQFQn1clk4xbBuQ03AdljEgmZtbZL6e1KCU8OVwnmCKpEMq5w0hLIBsPPoW/ixK4qhEpzC7CGXGuNWiusEjo56+NnQngbfhGieAwAyLokyDzH4wSx3QMIms73UvQ6fX2xoLFaPGSye/AAJ9hynkIgjwEAOq3+xileWaEMpaBMdwbLg06mQBioaS9qhUbUIJPyZCiq7xnO6D8SQqd0GxDLYwMala4sX/YoWyIWaLlVciodZbKp5hiO7CwIohCrlDItp6ujKwcNimD69yZisikRPW6OVqOXijQysVarJpxOlEpisMgMJzJCvDUOmkN0j+10HttKcrZN7B5bP3aPrR+7x9aP3WPrx+6x9fN/3UJv2CmEf4UAAAAASUVORK5CYII=",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Node\n",
    "def tool_calling_llm(state: MessagesState):\n",
    "    return {\"messages\": [llm_with_tools.invoke(state[\"messages\"])]}\n",
    "\n",
    "# Build graph\n",
    "builder = StateGraph(MessagesState)\n",
    "builder.add_node(\"tool_calling_llm\", tool_calling_llm)\n",
    "builder.add_node(\"tools\", ToolNode([multiply,add]))\n",
    "\n",
    "builder.add_edge(START, \"tool_calling_llm\")\n",
    "builder.add_conditional_edges(\n",
    "    \"tool_calling_llm\",\n",
    "    # If the latest message (result) from assistant is a tool call -> tools_condition routes to tools\n",
    "    # If the latest message (result) from assistant is a not a tool call -> tools_condition routes to END\n",
    "    tools_condition,\n",
    ")\n",
    "builder.add_edge(\"tools\", END)\n",
    "#builder.add_edge(\"tool2\", END)\n",
    "graph = builder.compile()\n",
    "\n",
    "# View\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Add 3 and 4. Multiply the output by 2 and add 5.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  add (call_eabXXmQTsnQRa5FW4b4QgP9U)\n",
      " Call ID: call_eabXXmQTsnQRa5FW4b4QgP9U\n",
      "  Args:\n",
      "    a: 3\n",
      "    b: 4\n",
      "  multiply (call_xPZ4d9WDt0sgSvGtrowA0QvJ)\n",
      " Call ID: call_xPZ4d9WDt0sgSvGtrowA0QvJ\n",
      "  Args:\n",
      "    a: 7\n",
      "    b: 2\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: add\n",
      "\n",
      "7\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: multiply\n",
      "\n",
      "14\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "messages = [HumanMessage(content=\"Add 3 and 4. Multiply the output by 2 and add 5.\")]\n",
    "messages = graph.invoke({\"messages\": messages})\n",
    "for m in messages['messages']:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
