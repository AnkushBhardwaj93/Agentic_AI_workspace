{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"GROQ_API_KEY\"] = os.getenv(\"GROQ_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x10d9092b0>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x10d810e60>, model_name='gemma2-9b-it', model_kwargs={}, groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "model=ChatGroq(model=\"gemma2-9b-it\")\n",
    "model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='I am Gemma, an open-weights AI assistant. I am a large language model trained by Google DeepMind. My purpose is to help people by understanding and responding to their requests in a helpful, informative, and impartial way. I can generate text, translate languages, write different kinds of creative content, and answer your questions in an informative way.\\n\\nSince I am open-weights, my weights are publicly accessible. This means that anyone can inspect, modify, or build upon me.\\n', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 101, 'prompt_tokens': 13, 'total_tokens': 114, 'completion_time': 0.183636364, 'prompt_time': 0.001942368, 'queue_time': 0.231702533, 'total_time': 0.185578732}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-d0326922-f3d0-4ab4-af80-f2b83bdaf75f-0', usage_metadata={'input_tokens': 13, 'output_tokens': 101, 'total_tokens': 114})"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.invoke(\"who are you?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hello Ankush, I am Gemma, an open-weights AI assistant. I'm a large language model, which means I'm trained on a massive amount of text data. This allows me to communicate and generate human-like text in response to a wide range of prompts and questions. For example, I can provide summaries of factual topics or create stories.\\n\\nWhat can I do for you today?\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 85, 'prompt_tokens': 21, 'total_tokens': 106, 'completion_time': 0.154545455, 'prompt_time': 0.002135298, 'queue_time': 0.23122801699999998, 'total_time': 0.156680753}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-f8ceeefa-286c-4e9c-b3f3-380b5905517d-0', usage_metadata={'input_tokens': 21, 'output_tokens': 85, 'total_tokens': 106})"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "model.invoke([HumanMessage(content=\"Hi, my name is ankush. who are you?\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"You are Ankush!  It's nice to meet you too. üòä  Is there anything you'd like to talk about?\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 31, 'prompt_tokens': 45, 'total_tokens': 76, 'completion_time': 0.056363636, 'prompt_time': 0.003442547, 'queue_time': 0.236827318, 'total_time': 0.059806183}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-c6a19ed1-cfc1-4524-b708-bc701f73e170-0', usage_metadata={'input_tokens': 45, 'output_tokens': 31, 'total_tokens': 76})"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import AIMessage\n",
    "model.invoke([\n",
    "    HumanMessage(content=\"Hi, my name is ankush. who are you?\"),\n",
    "    AIMessage(content=\"I am a language model\"),\n",
    "    HumanMessage(content=\"Nice to meet you. Who am i ?\")\n",
    "\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "\n",
    "store={}\n",
    "\n",
    "def get_session_history(session_id:str)->BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id]=ChatMessageHistory()\n",
    "    return store[session_id]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableWithMessageHistory(bound=RunnableBinding(bound=RunnableBinding(bound=RunnableLambda(_enter_history), kwargs={}, config={'run_name': 'load_history'}, config_factories=[])\n",
       "| RunnableBinding(bound=RunnableLambda(_call_runnable_sync), kwargs={}, config={'run_name': 'check_sync_or_async'}, config_factories=[]), kwargs={}, config={'run_name': 'RunnableWithMessageHistory'}, config_factories=[]), kwargs={}, config={}, config_factories=[], get_session_history=<function get_session_history at 0x10df982c0>, history_factory_config=[ConfigurableFieldSpec(id='session_id', annotation=<class 'str'>, name='Session ID', description='Unique identifier for a session.', default='', is_shared=True, dependencies=None)])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with_message_history= RunnableWithMessageHistory(model,get_session_history)\n",
    "with_message_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'configurable': {'session_id': 'ankush'}}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config={\"configurable\":{\"session_id\":\"ankush\"}}\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hello Ankush, nice to meet you! I am Gemma, an open-weights AI assistant. I'm a large language model, which means I'm trained on a massive amount of text data. This allows me to communicate and generate human-like text in response to a wide range of prompts and questions.\\n\\nWhat can I do for you today?\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 76, 'prompt_tokens': 21, 'total_tokens': 97, 'completion_time': 0.138181818, 'prompt_time': 0.002110348, 'queue_time': 0.232880337, 'total_time': 0.140292166}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-50626ede-2b62-4bb2-8acd-df39dfd6def9-0', usage_metadata={'input_tokens': 21, 'output_tokens': 76, 'total_tokens': 97})"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = with_message_history.invoke(  \n",
    "    [HumanMessage(content=\"Hi, my name is ankush. who are you?\")],\n",
    "    config=config\n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Based on our conversation so far, you are Ankush!  \\n\\nIs there anything else you'd like to tell me about yourself? üòä  \\n\\nI'm eager to learn more! \\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 43, 'prompt_tokens': 110, 'total_tokens': 153, 'completion_time': 0.078181818, 'prompt_time': 0.005277745, 'queue_time': 0.23408745, 'total_time': 0.083459563}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-9e943091-fd15-4f21-873c-c021849f59bd-0', usage_metadata={'input_tokens': 110, 'output_tokens': 43, 'total_tokens': 153})"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = with_message_history.invoke(  \n",
    "    [HumanMessage(content=\"who  am I ?\")],\n",
    "    config=config\n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hello Rishu, I am Gemma, an open-weights AI assistant. I'm here to help you with any questions you might have or to have a conversation with you about various topics.\\n\\nWhat can I do for you today?\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 51, 'prompt_tokens': 21, 'total_tokens': 72, 'completion_time': 0.092727273, 'prompt_time': 0.002134188, 'queue_time': 0.233096418, 'total_time': 0.094861461}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-e0ace8d9-32ce-4414-9727-7756490c0c9b-0', usage_metadata={'input_tokens': 21, 'output_tokens': 51, 'total_tokens': 72})"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config2={\"configurable\":{\"session_id\":\"Rishu\"}}\n",
    "response = with_message_history.invoke(  \n",
    "    [HumanMessage(content=\"Hi, my name is Rishu. who are you?\")],\n",
    "    config=config2\n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"You are Rishu, the person asking me questions!  \\n\\nIs there anything else you'd like to know about yourself, or would you like to talk about something else? üòä  \\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 41, 'prompt_tokens': 85, 'total_tokens': 126, 'completion_time': 0.074545455, 'prompt_time': 0.004046566, 'queue_time': 0.238649559, 'total_time': 0.078592021}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-075ff552-5d0a-421d-a9a3-9ac9689a0fe3-0', usage_metadata={'input_tokens': 85, 'output_tokens': 41, 'total_tokens': 126})"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = with_message_history.invoke(\n",
    "    [HumanMessage(content=\"who  am I ?\")],\n",
    "    config=config2\n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "InMemoryChatMessageHistory(messages=[HumanMessage(content='Hi, my name is ankush. who are you?', additional_kwargs={}, response_metadata={}), AIMessage(content=\"Hello Ankush, nice to meet you! I am Gemma, an open-weights AI assistant. I'm a large language model, which means I'm trained on a massive amount of text data. This allows me to communicate and generate human-like text in response to a wide range of prompts and questions.\\n\\nWhat can I do for you today?\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 76, 'prompt_tokens': 21, 'total_tokens': 97, 'completion_time': 0.138181818, 'prompt_time': 0.002110348, 'queue_time': 0.232880337, 'total_time': 0.140292166}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-50626ede-2b62-4bb2-8acd-df39dfd6def9-0', usage_metadata={'input_tokens': 21, 'output_tokens': 76, 'total_tokens': 97}), HumanMessage(content='who  am I ?', additional_kwargs={}, response_metadata={}), AIMessage(content=\"Based on our conversation so far, you are Ankush!  \\n\\nIs there anything else you'd like to tell me about yourself? üòä  \\n\\nI'm eager to learn more! \\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 43, 'prompt_tokens': 110, 'total_tokens': 153, 'completion_time': 0.078181818, 'prompt_time': 0.005277745, 'queue_time': 0.23408745, 'total_time': 0.083459563}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-9e943091-fd15-4f21-873c-c021849f59bd-0', usage_metadata={'input_tokens': 110, 'output_tokens': 43, 'total_tokens': 153})])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_session_history(\"ankush\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prompt Template\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\n",
    "    \"system\",\"You are a helpful person. answer questions in {language}\",\n",
    " \n",
    "),MessagesPlaceholder(variable_name=\"messages\")]\n",
    "\n",
    ")\n",
    "\n",
    "chain = prompt | model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'‡§®‡§Æ‡§∏‡•ç‡§§‡•á ‡§Ö‡§®‡§ï‡•Ç‡§∂!  üòä  ‡§Æ‡•Å‡§ù‡•á ‡§¨‡§π‡•Å‡§§ ‡§ñ‡•Å‡§∂‡•Ä ‡§π‡•à ‡§ï‡§ø ‡§Ü‡§™ ‡§Æ‡•Å‡§ù‡§∏‡•á ‡§¨‡§æ‡§§ ‡§ï‡§∞ ‡§∞‡§π‡•á ‡§π‡•à‡§Ç‡•§  ‡§Ü‡§™ ‡§ï‡•ç‡§Ø‡§æ ‡§ú‡§æ‡§®‡§®‡§æ ‡§ö‡§æ‡§π‡§§‡•á ‡§π‡•à‡§Ç?  \\n'"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = chain.invoke({\n",
    "    \"messages\": [HumanMessage(content=\"Hi, my name is ankush.\")],\n",
    "    \"language\": \"Hindi\"\n",
    "})\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='You are a helpful person. answer questions in Hindi', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='Nice to meet you. Who am i ?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='You are a helpful person. answer questions in Hindi', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='Hi, my name is rohit.', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='I am a language model', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='Nice to meet you. Who am i ?', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##trimming the response\n",
    "\n",
    "from langchain_core. messages import SystemMessage,trim_messages\n",
    "\n",
    "trimmer=trim_messages(\n",
    "    max_tokens=70,\n",
    "    token_counter=model,\n",
    "    strategy=\"last\",\n",
    "    start_on=\"human\",\n",
    "    allow_partial=False,\n",
    "    include_system=True\n",
    "    )\n",
    "\n",
    "messages=[\n",
    "    SystemMessage(content=\"You are a helpful person. answer questions in Hindi\"),\n",
    "    HumanMessage(content=\"Hi, my name is ankush.\"),\n",
    "    AIMessage(content=\"I am a language model\"),\n",
    "    HumanMessage(content=\"i like vnilla vanilla cream?\"),\n",
    "    AIMessage(content=\"You are a helpful person. answer questions in Hindi\"),\n",
    "    HumanMessage(content=\"Hi, my name is rishu.\"),\n",
    "    AIMessage(content=\"I am a language model\"),\n",
    "    HumanMessage(content=\"Nice to meet you. Who am i ?\"),\n",
    "    AIMessage(content=\"You are a helpful person. answer questions in Hindi\"),\n",
    "    HumanMessage(content=\"Hi, my name is rohit.\"),\n",
    "    AIMessage(content=\"I am a language model\"),\n",
    "    HumanMessage(content=\"Nice to meet you. Who am i ?\"),\n",
    "]\n",
    "\n",
    "trimmer.invoke(messages)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableAssign(mapper={\n",
       "  messages: RunnableLambda(itemgetter('messages'))\n",
       "            | RunnableLambda(...)\n",
       "})\n",
       "| ChatPromptTemplate(input_variables=['language', 'messages'], input_types={'messages': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x10ac40540>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]]}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['language'], input_types={}, partial_variables={}, template='You are a helpful person. answer questions in {language}'), additional_kwargs={}), MessagesPlaceholder(variable_name='messages')])\n",
       "| ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x10d9092b0>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x10d810e60>, model_name='gemma2-9b-it', model_kwargs={}, groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from operator import itemgetter\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "chain=(RunnablePassthrough.assign(messages=itemgetter('messages')| trimmer) |prompt| model)\n",
    "\n",
    "chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='‡§Ü‡§™‡§ï‡•á ‡§®‡§æ‡§Æ ‡§∞‡•ã‡§π‡§ø‡§§ ‡§π‡•à‡§Ç‡•§  üòä \\n', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 105, 'total_tokens': 119, 'completion_time': 0.025454545, 'prompt_time': 0.00554142, 'queue_time': 0.235255445, 'total_time': 0.030995965}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-ffe2a1c1-6931-4d5c-80f8-e060ae1e5e9c-0', usage_metadata={'input_tokens': 105, 'output_tokens': 14, 'total_tokens': 119})"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\n",
    "    \"messages\": messages+[HumanMessage(content=\"what are my names\")],\n",
    "    \"language\":\"Hindi\"\n",
    "\n",
    "})\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
